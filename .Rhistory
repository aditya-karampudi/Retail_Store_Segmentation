rm(list = ls(all.names = TRUE))
setwd("C://Users//mohad//OneDrive//Desktop//New_Github//Retail_Store_Segmentation")
getwd()
dataretail<-read.csv("DataRetail.csv", header = T, sep=",")
library(lubridate)
############ extracting date ########
dataretail$Transaction.Time<-dmy_hm(dataretail$Transaction.Time)
dataretail$Transaction.Time<-as.Date( as.POSIXlt(dataretail$Transaction.Time,tz= "UTC"))
head(dataretail$Transaction.Time)
##MOnetary(total amount spend by each customer)
library(dplyr)
data_rt<- dataretail %>%
group_by(CustomerID) %>%
summarise(sumcost=sum(Cost), no.ofproducts = length(ProductID), mins=min(Cost),maxs=max(Cost)) %>%
as.data.frame
DT = unique(dataretail[c("CustomerID", "TransactionID")])
data_rt$Frequency=aggregate(TransactionID ~ CustomerID, DT, function(x) length(unique(x)))$TransactionID
rm(DT)
##first and last arrival date of each customer
first_last_date<-dataretail %>% group_by(CustomerID) %>% summarise(FirstDate = min(Transaction.Time), LastDate = max(Transaction.Time)  ) %>%
as.data.frame
first_last_date$CustomerID<-NULL
data_rt$CustomerID<- NULL
##No. of days in-between first arrival &last arrival of each customer
y<- as.Date("31/12/2016", format="%d/%m/%Y")
recency<- as.data.frame(y-first_last_date$LastDate) #subracting last date visitdate(each cust)
tenure<-as.data.frame(first_last_date$LastDate-first_last_date$FirstDate);
data_rt<- cbind(data_rt,first_last_date, recency,tenure)  #check data_set
##removing unwanted
first_last_date<-NULL
data_rt$FirstDate<- NULL
data_rt$LastDate<- NULL
recency<- NULL
##final dataset
names(data_rt) <- c("Revenue","Quantity","Minimum Cost","Maximum Cost", "Frequency", "Recency","Tenure") # And change names
str(data_rt)
data_rt$Recency=as.integer(data_rt$Recency)
data_rt$Tenure=as.integer(data_rt$Tenure)
data_rt1=as.data.frame(data_rt)
####standardizing the data for clustering###############
library(vegan)
data_std<-decostand(data_rt1,"standardize",MARGIN = 2)
sum((is.na(data_std)))
data_std_hclust<-data_std## copy of data for hclust
install.packages("vegan")
####standardizing the data for clustering###############
library(vegan)
data_std<-decostand(data_rt1,"standardize",MARGIN = 2)
sum((is.na(data_std)))
data_std_hclust<-data_std## copy of data for hclust
data_std_hclust1<-data_std
######Applying Hierarchial CLustering #####
distmatrix <- dist(data_std_hclust,method = "euclidean") # distance matrix
retail_hclust <- hclust(distmatrix, method="ward.D2")
plot(retail_hclust) # display dendogram
groups <- cutree(retail_hclust, k=6)
groups
rect.hclust(retail_hclust, k=6, border="red")
data_std_hclust$cluster <- groups
head(data_std_hclust)
####To check NO of ouliers###
a=summary(data_rt$Revenue)[5]-summary(data_rt$Revenue)[2]
b=(1.5*a) +summary(data_rt$Revenue)[5]
c= - (1.5*a) +summary(data_rt$Revenue)[2]
d=nrow(subset(data_rt, Revenue>b))
e=nrow(subset(data_rt, Revenue<c))
library(dplyr)
data_std_hclust %>%
group_by(cluster) %>%
summarise(No_of_obs = n())
summary(retail_hclust)
####Applying K-means Algorithm######
# Determine number of clusters by considering the withinness measure
wss <- 0
for (i in 1:15) {
wss[i] <- sum(kmeans(data_std,centers=i)$withinss)
}
#Scree Plot
plot(1:15, wss,
type="b",
xlab="Number of Clusters",
ylab="Within groups sum of squares")
#############fit6################
fit6<-kmeans(data_std,6)
#With-in sum of squares in each cluster
fit6$withinss
sum(fit6$withinss)  ##suming withinss
summary(fit6)
###Insight
fit6$centers
fit6$size
#To check cluster number of each row in data
Cluster_No.<-fit6$cluster
#Cluster Centers
Cluster_Centres<-fit6$centers
# get cluster means
aggregate(data_std,by=list(fit6$cluster),FUN=mean)
# append cluster label to the actual data frame
fit6_withclusterNo <- data.frame(data_rt1,fit6$cluster)
head(fit6_withclusterNo)
fit6_withclusterNo$fit6.cluster<-as.factor(fit6_withclusterNo$fit6.cluster)
fit6_withclusterNo$Quantity<-as.numeric(fit6_withclusterNo$Quantity)
str(fit6_withclusterNo)
library(dplyr)
fit6_withclusterNo %>%
group_by(fit6.cluster) %>%
summarise(No_of_obs = n())
comb= cbind(data_rt1,CustomerID= unique(dataretail$CustomerID))
score_data=as.data.frame(comb)
str(score_data)
score_data$Tenure = ifelse(score_data$Tenure==0,0.1,score_data$Tenure)
score_data$Recency = ifelse(score_data$Recency==0,1,score_data$Recency)
score_data$Quantity<-as.numeric(score_data$Quantity)
score_data$Score=(score_data$Revenue)*sqrt(score_data$Frequency)*(score_data$Quantity)/sqrt(score_data$Recency)
k = quantile(score_data$Score,0.9)
score_data$Score = scale(score_data$Score, center = FALSE, scale = k/100)
Sub = subset(score_data, Revenue > 500)
score_data$Score=ifelse(score_data$Score>100,100,score_data$Score)
summary(score_data$Score)
table(round(score_data$Score))
#####BOX PLOT of clusters################
fit6$centers
Boxplot<-boxplot(fit6$centers[1:6])
Boxplot<-boxplot(fit6$centers[37:42])
#####dividind into train and test for classification##############
rows<-seq(1,nrow(fit6_withclusterNo),1)
set.seed(1234)
trainrows<-sample(rows,0.7*nrow(fit6_withclusterNo))
Train<-fit6_withclusterNo[trainrows,]
Test<-fit6_withclusterNo[-trainrows,]
fit6_withclusterNo$Quantity<-as.numeric(fit6_withclusterNo$Quantity)
library(C50)
Model_C50 <-C5.0(Train[,-8],Train[,8])
Model_C50
summary(Model_C50)
library(caret)
